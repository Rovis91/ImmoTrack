"""
Parser module for extracting structured data from HTML property elements.
"""
import json
import logging
import pandas as pd
from datetime import datetime
from typing import Dict, Optional
from bs4 import BeautifulSoup
from .processor_base import ProcessorBase

logger = logging.getLogger(__name__)

class DataParser(ProcessorBase):
    """Extracts structured data from raw HTML property elements."""

    def _parse_property(self, html_content: str) -> Optional[Dict]:
        """
        Parse a single property's HTML content.
        
        Args:
            html_content: Raw HTML string
            
        Returns:
            Dict of parsed property data if successful, None otherwise
        """
        try:
            soup = BeautifulSoup(html_content, 'lxml')
            property_data = {}

            # Address
            address_tag = soup.find('p', class_='text-gray-700 font-bold truncate')
            if address_tag:
                address = address_tag.text.strip()
                if ' - ' in address:
                    parts = address.rsplit(' - ', 1)
                    property_data["complete_address"] = parts[0].strip()
                    property_data["city_name"] = parts[1].strip()
                else:
                    property_data["complete_address"] = address
                    property_data["city_name"] = ""

            # Property type
            type_tag = soup.find('p', class_='flex items-center text-sm text-gray-400')
            property_data["property_type"] = type_tag.span.text.strip() if type_tag and type_tag.span else ""

            # Price
            price_tag = soup.find('p', class_='text-primary-500 font-bold whitespace-nowrap')
            if price_tag and price_tag.span:
                price_text = price_tag.span.text.replace('â‚¬', '').replace(' ', '').replace('.', '')
                property_data["price"] = int(price_text) if price_text.isdigit() else 0
            else:
                property_data["price"] = 0

            # Number of rooms
            rooms_tag = (
                soup.find('svg', class_='fa-objects-column')
                .find_next('span', class_='font-semibold') 
                if soup.find('svg', class_='fa-objects-column') else None
            )
            property_data["rooms"] = int(rooms_tag.text.strip()) if rooms_tag else None

            # Surface area
            surface_tag = (
                soup.find('svg', class_='fa-ruler-combined')
                .find_next('span', class_='font-semibold') 
                if soup.find('svg', class_='fa-ruler-combined') else None
            )
            if surface_tag:
                surface_text = surface_tag.text.replace(',', '.').strip()
                property_data["surface_area"] = float(surface_text) if surface_text.replace('.', '').isdigit() else None
            else:
                property_data["surface_area"] = None

            # Mutation date
            date_tag = soup.find('time')
            if date_tag and date_tag.get('datetime'):
                try:
                    timestamp = int(date_tag['datetime']) // 1000
                    mutation_date = datetime.fromtimestamp(timestamp)
                    property_data["mutation_date"] = mutation_date.strftime('%d/%m/%Y')
                except (ValueError, TypeError) as e:
                    logger.warning(f"Failed to parse mutation date: {e}")
                    property_data["mutation_date"] = None
            else:
                property_data["mutation_date"] = None

            # Analysis link
            analysis_link = soup.find('a', attrs={
                'class': lambda x: x and all(c in x.split() for c in ['whitespace-nowrap', 'border', 'bg-primary-500'])
            })
            if analysis_link and analysis_link.get('href'):
                href = analysis_link.get('href')
                property_data["analysis_url"] = f"https://www.immo-data.fr{href}" if href.startswith('/') else href
            else:
                logger.warning(f"Analysis link not found in HTML")

            return property_data

        except Exception as e:
            logger.error(f"Error parsing property: {e}")
            return None

    def _remove_duplicates(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Remove duplicate entries based on address and mutation date.
        
        Args:
            df: DataFrame containing property data
            
        Returns:
            DataFrame with duplicates removed
        """
        try:
            initial_count = len(df)
            logger.info(f"Removing duplicates from {initial_count} properties...")
            # Remove duplicates based on address and date
            df_no_duplicates = df.drop_duplicates(
                subset=['complete_address', 'mutation_date'],
                keep='first'
            )
            
            removed_count = initial_count - len(df_no_duplicates)
            if removed_count > 0:
                logger.info(
                    f"Removed {removed_count} duplicate properties "
                    f"({(removed_count/initial_count)*100:.1f}% of total)"
                )
            
            return df_no_duplicates
            
        except Exception as e:
            logger.error(f"Error removing duplicates: {e}")
            return df  # Return original DataFrame if deduplication fails

    def process(self, input_path: str, output_path: str) -> bool:
        """
        Process raw scraping data and save parsed results.
        """
        try:
            # First load the raw JSON file properly
            with open(input_path, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)

            # Parse all properties
            parsed_properties = []
            total_count = 0

            # Iterate through results structure
            for result in raw_data.get("results", []):
                for property_data in result.get("properties", []):
                    total_count += 1
                    if html_content := property_data.get("html"):
                        if parsed_prop := self._parse_property(html_content):
                            parsed_properties.append(parsed_prop)
                            
            if not parsed_properties:
                logger.error("No properties were successfully parsed")
                return False

            # Convert parsed data to DataFrame
            parsed_df = pd.DataFrame(parsed_properties)
            
            # Remove duplicates before saving
            parsed_df = self._remove_duplicates(parsed_df)
            
            # Log parsing results
            success_rate = (len(parsed_df) / total_count * 100) if total_count > 0 else 0
            logger.info(f"Parsed {len(parsed_df)}/{total_count} properties ({success_rate:.1f}%)")
            
            # Save using parent class method
            return self.save_csv(parsed_df, output_path)

        except Exception as e:
            logger.error(f"Parsing failed: {str(e)}")
            logger.debug("Error details:", exc_info=True)
            return False